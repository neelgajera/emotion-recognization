{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Copy of imbalanced_data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVwEctrlRH9Q"
      },
      "source": [
        "import requests\r\n",
        "re = requests.get('https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/3364/31151/compressed/icml_face_data.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1614840286&Signature=O3CTEnHe1EWfpkfuLEDfM7a4eWSpEP8z8%2BIQBT95ARnwxy%2Bp1OHhkUwgcQ3pJGfC1bP%2By5vCPp1f7dn95ZpVlSYbcYsKEwkiMHMGgAC1lB2G5epkZ9jwhRUR1Ws19z9jo%2BtrNjkR5AaEJdKZiKc20Cow5g%2FFj%2BHhRzXA%2BOi%2FFOh2TbAhHAF8S7inf7rNmUq7VgGreTiS%2B6Uy0zF8kGnMru7qUGWrPzhJdcQOtmF6Zzccr3CR5GHIVo%2B47xYt4ueHDuGRq1mOGHPGibDd1KwVPJpe5%2FfJkTkVM%2FDHax5rTOHkCT6nc3qb6XYumYmg%2BQxlxBrEqM3xq2Q%2FYqSkNYbQPQ%3D%3D&response-content-disposition=attachment%3B+filename%3Dicml_face_data.csv.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLy7tnV-ZR3t"
      },
      "source": [
        "with open('/content/train.csv.zip', 'wb') as fd:\r\n",
        "        for chunk in re.iter_content(chunk_size=128):\r\n",
        "            fd.write(chunk)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoNxgQUSaHOR"
      },
      "source": [
        "import zipfile\r\n",
        "with zipfile.ZipFile(\"/content/train.csv.zip\",\"r\") as zip_ref:\r\n",
        "    zip_ref.extractall(\"/content/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcT9U7IsbWFZ"
      },
      "source": [
        "import pandas as pd\r\n",
        "row_data = pd.read_csv('/content/icml_face_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "NWvAnthwcT7I",
        "outputId": "b7f4cc1d-a04d-499d-b5f3-6d15dd2087c6"
      },
      "source": [
        "row_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>Usage</th>\n",
              "      <th>pixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Training</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Training</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Training</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Training</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>Training</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35882</th>\n",
              "      <td>6</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35883</th>\n",
              "      <td>3</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>178 174 172 173 181 188 191 194 196 199 200 20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35884</th>\n",
              "      <td>0</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35885</th>\n",
              "      <td>3</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35886</th>\n",
              "      <td>2</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35887 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       emotion        Usage                                             pixels\n",
              "0            0     Training  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
              "1            0     Training  151 150 147 155 148 133 111 140 170 174 182 15...\n",
              "2            2     Training  231 212 156 164 174 138 161 173 182 200 106 38...\n",
              "3            4     Training  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
              "4            6     Training  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...\n",
              "...        ...          ...                                                ...\n",
              "35882        6  PrivateTest  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...\n",
              "35883        3  PrivateTest  178 174 172 173 181 188 191 194 196 199 200 20...\n",
              "35884        0  PrivateTest  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...\n",
              "35885        3  PrivateTest  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...\n",
              "35886        2  PrivateTest  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...\n",
              "\n",
              "[35887 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nusRh8dBfEME",
        "outputId": "29a8a114-9891-4eac-dec8-16aa4b4d4422"
      },
      "source": [
        "import tensorflow.keras as keras\r\n",
        "%pylab inline\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "# from matplotlib.pyplot import imread\r\n",
        "# import imageio\r\n",
        "from matplotlib import image\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Convolution2D, Flatten, MaxPooling2D, Reshape, InputLayer\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from tensorflow.keras.preprocessing.image import load_img\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['re']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPWuilQzdVRt"
      },
      "source": [
        "def prepare_data(data):\r\n",
        "    \"\"\" Prepare data for modeling \r\n",
        "        input: data frame with labels und pixel data\r\n",
        "        output: image and label array \"\"\"\r\n",
        "    \r\n",
        "    image_array = np.zeros(shape=(len(data), 48, 48))\r\n",
        "    image_label = np.array(list(map(int, data['emotion'])))\r\n",
        "    \r\n",
        "    for i, row in enumerate(data.index):\r\n",
        "        image = np.fromstring(data.loc[row, ' pixels'], dtype=int, sep=' ')\r\n",
        "        image = np.reshape(image, (48, 48))\r\n",
        "        image_array[i] = image\r\n",
        "        \r\n",
        "    return image_array, image_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4mDYfQvfNZV"
      },
      "source": [
        "train_image_array, train_image_label = prepare_data(row_data[:27000])\r\n",
        "val_image_array, val_image_label = prepare_data(row_data[27000:28000])\r\n",
        "test_image_array, test_image_label = prepare_data(row_data[28000:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L80lwwlisEN"
      },
      "source": [
        "train_images = train_image_array.reshape((train_image_array.shape[0], 48, 48, 1))\r\n",
        "X_train = train_images.astype('float32')/255\r\n",
        "val_images = val_image_array.reshape((val_image_array.shape[0], 48, 48, 1))\r\n",
        "X_val = val_images.astype('float32')/255\r\n",
        "test_images = test_image_array.reshape((test_image_array.shape[0], 48, 48, 1))\r\n",
        "X_test = test_images.astype('float32')/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2CjAR0oiwVs"
      },
      "source": [
        "y_train = keras.utils.to_categorical(train_image_label)\r\n",
        "y_val = keras.utils.to_categorical(val_image_label)\r\n",
        "y_test = keras.utils.to_categorical(test_image_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSIeUfolhwSF"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop,SGD,Adam\r\n",
        "from tensorflow.keras import optimizers\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y6YKYeQh0uE"
      },
      "source": [
        "checkpoint = ModelCheckpoint('EmotionDetectionModel.h5',\r\n",
        "                             monitor='val_loss',\r\n",
        "                             mode='min',\r\n",
        "                             save_best_only=True,\r\n",
        "                             verbose=1)\r\n",
        "earlystop = EarlyStopping(monitor='val_loss',\r\n",
        "                          min_delta=0,\r\n",
        "                          patience=20,\r\n",
        "                          verbose=1,\r\n",
        "                          restore_best_weights=True\r\n",
        "                          )\r\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\r\n",
        "                              factor=0.2,\r\n",
        "                              patience=20,\r\n",
        "                              verbose=1,\r\n",
        "                              min_delta=0.0001)\r\n",
        "callbacks = [earlystop,checkpoint,reduce_lr]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0V-uWCNs5T7",
        "outputId": "47f8df9d-1fa2-4da6-a7be-c641639cc068"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFquYs32tC9y"
      },
      "source": [
        "!cp /content/EmotionDetectionModel.h5  /content/drive/MyDrive/Models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmlbtr18AfqE"
      },
      "source": [
        "# As the data in hand is less as compared to the task so ImageDataGenerator is good to go.\r\n",
        "train_datagen = ImageDataGenerator(\r\n",
        "    rotation_range=15,\r\n",
        "    width_shift_range=0.15,\r\n",
        "    height_shift_range=0.15,\r\n",
        "    shear_range=0.15,\r\n",
        "    zoom_range=0.15,\r\n",
        "    horizontal_flip=True,\r\n",
        ")\r\n",
        "train_datagen.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlWyFCMMAHog"
      },
      "source": [
        "import math\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "\r\n",
        "import seaborn as sns\r\n",
        "from matplotlib import pyplot\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras import optimizers\r\n",
        "from tensorflow.keras.datasets import mnist\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D\r\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU, Activation\r\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbI2-Oqu-d5H"
      },
      "source": [
        "def build_net(optim):\r\n",
        "    \"\"\"\r\n",
        "    This is a Deep Convolutional Neural Network (DCNN). For generalization purpose I used dropouts in regular intervals.\r\n",
        "    I used `ELU` as the activation because it avoids dying relu problem but also performed well as compared to LeakyRelu\r\n",
        "    atleast in this case. `he_normal` kernel initializer is used as it suits ELU. BatchNormalization is also used for better\r\n",
        "    results.\r\n",
        "    \"\"\"\r\n",
        "    net = Sequential(name='DCNN')\r\n",
        "\r\n",
        "    net.add(\r\n",
        "        Conv2D(\r\n",
        "            filters=64,\r\n",
        "            kernel_size=(5,5),\r\n",
        "            input_shape=(48, 48, 1),\r\n",
        "            activation='elu',\r\n",
        "            padding='same',\r\n",
        "            kernel_initializer='he_normal',\r\n",
        "            name='conv2d_1'\r\n",
        "        )\r\n",
        "    )\r\n",
        "    net.add(BatchNormalization(name='batchnorm_1'))\r\n",
        "    net.add(\r\n",
        "        Conv2D(\r\n",
        "            filters=64,\r\n",
        "            kernel_size=(5,5),\r\n",
        "            activation='elu',\r\n",
        "            padding='same',\r\n",
        "            kernel_initializer='he_normal',\r\n",
        "            name='conv2d_2'\r\n",
        "        )\r\n",
        "    )\r\n",
        "    net.add(BatchNormalization(name='batchnorm_2'))\r\n",
        "    \r\n",
        "    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_1'))\r\n",
        "    net.add(Dropout(0.4, name='dropout_1'))\r\n",
        "\r\n",
        "    net.add(\r\n",
        "        Conv2D(\r\n",
        "            filters=128,\r\n",
        "            kernel_size=(3,3),\r\n",
        "            activation='elu',\r\n",
        "            padding='same',\r\n",
        "            kernel_initializer='he_normal',\r\n",
        "            name='conv2d_3'\r\n",
        "        )\r\n",
        "    )\r\n",
        "    net.add(BatchNormalization(name='batchnorm_3'))\r\n",
        "    net.add(\r\n",
        "        Conv2D(\r\n",
        "            filters=128,\r\n",
        "            kernel_size=(3,3),\r\n",
        "            activation='elu',\r\n",
        "            padding='same',\r\n",
        "            kernel_initializer='he_normal',\r\n",
        "            name='conv2d_4'\r\n",
        "        )\r\n",
        "    )\r\n",
        "    net.add(BatchNormalization(name='batchnorm_4'))\r\n",
        "    \r\n",
        "    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_2'))\r\n",
        "    net.add(Dropout(0.4, name='dropout_2'))\r\n",
        "\r\n",
        "    net.add(\r\n",
        "        Conv2D(\r\n",
        "            filters=256,\r\n",
        "            kernel_size=(3,3),\r\n",
        "            activation='elu',\r\n",
        "            padding='same',\r\n",
        "            kernel_initializer='he_normal',\r\n",
        "            name='conv2d_5'\r\n",
        "        )\r\n",
        "    )\r\n",
        "    net.add(BatchNormalization(name='batchnorm_5'))\r\n",
        "    net.add(\r\n",
        "        Conv2D(\r\n",
        "            filters=256,\r\n",
        "            kernel_size=(3,3),\r\n",
        "            activation='elu',\r\n",
        "            padding='same',\r\n",
        "            kernel_initializer='he_normal',\r\n",
        "            name='conv2d_6'\r\n",
        "        )\r\n",
        "    )\r\n",
        "    net.add(BatchNormalization(name='batchnorm_6'))\r\n",
        "    \r\n",
        "    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_3'))\r\n",
        "    net.add(Dropout(0.5, name='dropout_3'))\r\n",
        "\r\n",
        "    net.add(Flatten(name='flatten'))\r\n",
        "        \r\n",
        "    net.add(\r\n",
        "        Dense(\r\n",
        "            128,\r\n",
        "            activation='elu',\r\n",
        "            kernel_initializer='he_normal',\r\n",
        "            name='dense_1'\r\n",
        "        )\r\n",
        "    )\r\n",
        "    net.add(BatchNormalization(name='batchnorm_7'))\r\n",
        "    net.add(Dropout(0.2, name='dropout_5'))\r\n",
        "    net.add(\r\n",
        "        Dense(\r\n",
        "            128,\r\n",
        "            activation='elu',\r\n",
        "            kernel_initializer='he_normal',\r\n",
        "            name='dense_2'\r\n",
        "        )\r\n",
        "    )\r\n",
        "    net.add(BatchNormalization(name='batchnorm_8'))\r\n",
        "    \r\n",
        "    net.add(Dropout(0.6, name='dropout_4'))\r\n",
        "    \r\n",
        "    net.add(\r\n",
        "        Dense(\r\n",
        "            7,\r\n",
        "            activation='softmax',\r\n",
        "            name='out_layer'\r\n",
        "        )\r\n",
        "    )\r\n",
        "    \r\n",
        "    net.compile(\r\n",
        "        loss='categorical_crossentropy',\r\n",
        "        optimizer=optim,\r\n",
        "        metrics=['accuracy']\r\n",
        "    )\r\n",
        "    \r\n",
        "    net.summary()\r\n",
        "    \r\n",
        "    return net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heF3Puyw--1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfef4208-3f91-4433-a874-db54466c2b4c"
      },
      "source": [
        "batch_size = 128 #batch size of 32 performs the best.\r\n",
        "epochs = 100\r\n",
        "optims = [\r\n",
        "    optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name='Nadam'),\r\n",
        "    optimizers.Adam(0.001),\r\n",
        "]\r\n",
        "model = build_net(optims[1]) \r\n",
        "history = model.fit(\r\n",
        "    train_datagen.flow(X_train, y_train, batch_size=batch_size),\r\n",
        "    validation_data=(X_val, y_val),\r\n",
        "    steps_per_epoch=len(X_train) / batch_size,\r\n",
        "    epochs=epochs,\r\n",
        "    callbacks=callbacks\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"DCNN\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 48, 48, 64)        1664      \n",
            "_________________________________________________________________\n",
            "batchnorm_1 (BatchNormalizat (None, 48, 48, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 48, 48, 64)        102464    \n",
            "_________________________________________________________________\n",
            "batchnorm_2 (BatchNormalizat (None, 48, 48, 64)        256       \n",
            "_________________________________________________________________\n",
            "maxpool2d_1 (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batchnorm_3 (BatchNormalizat (None, 24, 24, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 24, 24, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batchnorm_4 (BatchNormalizat (None, 24, 24, 128)       512       \n",
            "_________________________________________________________________\n",
            "maxpool2d_2 (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 12, 12, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batchnorm_5 (BatchNormalizat (None, 12, 12, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batchnorm_6 (BatchNormalizat (None, 12, 12, 256)       1024      \n",
            "_________________________________________________________________\n",
            "maxpool2d_3 (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "batchnorm_7 (BatchNormalizat (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "batchnorm_8 (BatchNormalizat (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 7)                 903       \n",
            "=================================================================\n",
            "Total params: 2,412,615\n",
            "Trainable params: 2,410,311\n",
            "Non-trainable params: 2,304\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "210/210 [==============================] - 36s 157ms/step - loss: 2.7741 - accuracy: 0.1775 - val_loss: 1.8008 - val_accuracy: 0.2960\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 1.77800\n",
            "Epoch 2/100\n",
            "210/210 [==============================] - 31s 149ms/step - loss: 1.9868 - accuracy: 0.2343 - val_loss: 1.6853 - val_accuracy: 0.3440\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.77800 to 1.68531, saving model to EmotionDetectionModel.h5\n",
            "Epoch 3/100\n",
            "210/210 [==============================] - 31s 149ms/step - loss: 1.7919 - accuracy: 0.2742 - val_loss: 1.5686 - val_accuracy: 0.3840\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.68531 to 1.56864, saving model to EmotionDetectionModel.h5\n",
            "Epoch 4/100\n",
            "210/210 [==============================] - 32s 149ms/step - loss: 1.6937 - accuracy: 0.3243 - val_loss: 1.5374 - val_accuracy: 0.3960\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.56864 to 1.53742, saving model to EmotionDetectionModel.h5\n",
            "Epoch 5/100\n",
            "210/210 [==============================] - 32s 149ms/step - loss: 1.6102 - accuracy: 0.3711 - val_loss: 1.4640 - val_accuracy: 0.4520\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.53742 to 1.46402, saving model to EmotionDetectionModel.h5\n",
            "Epoch 6/100\n",
            "210/210 [==============================] - 31s 148ms/step - loss: 1.4975 - accuracy: 0.4215 - val_loss: 1.3395 - val_accuracy: 0.4950\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.46402 to 1.33951, saving model to EmotionDetectionModel.h5\n",
            "Epoch 7/100\n",
            "210/210 [==============================] - 31s 149ms/step - loss: 1.4350 - accuracy: 0.4450 - val_loss: 1.3498 - val_accuracy: 0.4880\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.33951\n",
            "Epoch 8/100\n",
            "210/210 [==============================] - 31s 148ms/step - loss: 1.3691 - accuracy: 0.4787 - val_loss: 1.2378 - val_accuracy: 0.5400\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.33951 to 1.23781, saving model to EmotionDetectionModel.h5\n",
            "Epoch 9/100\n",
            "210/210 [==============================] - 31s 148ms/step - loss: 1.3192 - accuracy: 0.5028 - val_loss: 1.3571 - val_accuracy: 0.4920\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.23781\n",
            "Epoch 10/100\n",
            "210/210 [==============================] - 31s 148ms/step - loss: 1.2950 - accuracy: 0.5118 - val_loss: 1.1086 - val_accuracy: 0.5940\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.23781 to 1.10855, saving model to EmotionDetectionModel.h5\n",
            "Epoch 11/100\n",
            "210/210 [==============================] - 31s 149ms/step - loss: 1.2440 - accuracy: 0.5300 - val_loss: 1.0925 - val_accuracy: 0.5910\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.10855 to 1.09253, saving model to EmotionDetectionModel.h5\n",
            "Epoch 12/100\n",
            "210/210 [==============================] - 31s 149ms/step - loss: 1.2244 - accuracy: 0.5354 - val_loss: 1.0850 - val_accuracy: 0.5850\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.09253 to 1.08498, saving model to EmotionDetectionModel.h5\n",
            "Epoch 13/100\n",
            "210/210 [==============================] - 31s 149ms/step - loss: 1.1929 - accuracy: 0.5480 - val_loss: 1.0633 - val_accuracy: 0.5920\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.08498 to 1.06327, saving model to EmotionDetectionModel.h5\n",
            "Epoch 14/100\n",
            "210/210 [==============================] - 32s 149ms/step - loss: 1.1722 - accuracy: 0.5605 - val_loss: 1.0606 - val_accuracy: 0.6000\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.06327 to 1.06059, saving model to EmotionDetectionModel.h5\n",
            "Epoch 15/100\n",
            "210/210 [==============================] - 32s 149ms/step - loss: 1.1582 - accuracy: 0.5649 - val_loss: 1.0607 - val_accuracy: 0.6040\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.06059\n",
            "Epoch 16/100\n",
            "210/210 [==============================] - 32s 149ms/step - loss: 1.1483 - accuracy: 0.5682 - val_loss: 1.0525 - val_accuracy: 0.6110\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.06059 to 1.05247, saving model to EmotionDetectionModel.h5\n",
            "Epoch 17/100\n",
            "210/210 [==============================] - 31s 149ms/step - loss: 1.1236 - accuracy: 0.5767 - val_loss: 1.0042 - val_accuracy: 0.6240\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.05247 to 1.00423, saving model to EmotionDetectionModel.h5\n",
            "Epoch 18/100\n",
            "210/210 [==============================] - 31s 149ms/step - loss: 1.1086 - accuracy: 0.5855 - val_loss: 0.9971 - val_accuracy: 0.6290\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.00423 to 0.99715, saving model to EmotionDetectionModel.h5\n",
            "Epoch 19/100\n",
            "210/210 [==============================] - 32s 149ms/step - loss: 1.0949 - accuracy: 0.5953 - val_loss: 1.0058 - val_accuracy: 0.6260\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.99715\n",
            "Epoch 20/100\n",
            "210/210 [==============================] - 32s 149ms/step - loss: 1.0912 - accuracy: 0.5942 - val_loss: 0.9631 - val_accuracy: 0.6510\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.99715 to 0.96311, saving model to EmotionDetectionModel.h5\n",
            "Epoch 21/100\n",
            "210/210 [==============================] - 32s 149ms/step - loss: 1.0862 - accuracy: 0.5971 - val_loss: 0.9854 - val_accuracy: 0.6320\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.96311\n",
            "Epoch 22/100\n",
            "210/210 [==============================] - 31s 148ms/step - loss: 1.0674 - accuracy: 0.6013 - val_loss: 0.9632 - val_accuracy: 0.6440\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.96311\n",
            "Epoch 23/100\n",
            "210/210 [==============================] - 31s 149ms/step - loss: 1.0563 - accuracy: 0.6108 - val_loss: 0.9420 - val_accuracy: 0.6550\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.96311 to 0.94204, saving model to EmotionDetectionModel.h5\n",
            "Epoch 24/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 1.0488 - accuracy: 0.6114 - val_loss: 0.9264 - val_accuracy: 0.6530\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.94204 to 0.92642, saving model to EmotionDetectionModel.h5\n",
            "Epoch 25/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 1.0427 - accuracy: 0.6109 - val_loss: 0.9619 - val_accuracy: 0.6460\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.92642\n",
            "Epoch 26/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 1.0344 - accuracy: 0.6165 - val_loss: 0.9256 - val_accuracy: 0.6620\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.92642 to 0.92564, saving model to EmotionDetectionModel.h5\n",
            "Epoch 27/100\n",
            "210/210 [==============================] - 32s 149ms/step - loss: 1.0201 - accuracy: 0.6268 - val_loss: 0.9371 - val_accuracy: 0.6620\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.92564\n",
            "Epoch 28/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 1.0223 - accuracy: 0.6211 - val_loss: 0.9421 - val_accuracy: 0.6430\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.92564\n",
            "Epoch 29/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 1.0111 - accuracy: 0.6271 - val_loss: 0.9383 - val_accuracy: 0.6560\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.92564\n",
            "Epoch 30/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 1.0018 - accuracy: 0.6351 - val_loss: 0.9540 - val_accuracy: 0.6420\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.92564\n",
            "Epoch 31/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 0.9986 - accuracy: 0.6282 - val_loss: 0.9166 - val_accuracy: 0.6670\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.92564 to 0.91655, saving model to EmotionDetectionModel.h5\n",
            "Epoch 32/100\n",
            "210/210 [==============================] - 31s 149ms/step - loss: 0.9861 - accuracy: 0.6332 - val_loss: 0.8995 - val_accuracy: 0.6660\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.91655 to 0.89954, saving model to EmotionDetectionModel.h5\n",
            "Epoch 33/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 0.9792 - accuracy: 0.6376 - val_loss: 0.9224 - val_accuracy: 0.6720\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.89954\n",
            "Epoch 34/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 0.9761 - accuracy: 0.6422 - val_loss: 0.9432 - val_accuracy: 0.6620\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.89954\n",
            "Epoch 35/100\n",
            "210/210 [==============================] - 32s 149ms/step - loss: 0.9826 - accuracy: 0.6348 - val_loss: 0.9056 - val_accuracy: 0.6780\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.89954\n",
            "Epoch 36/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 0.9655 - accuracy: 0.6403 - val_loss: 0.9014 - val_accuracy: 0.6710\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.89954\n",
            "Epoch 37/100\n",
            "210/210 [==============================] - 31s 149ms/step - loss: 0.9656 - accuracy: 0.6425 - val_loss: 0.9443 - val_accuracy: 0.6560\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.89954\n",
            "Epoch 38/100\n",
            "210/210 [==============================] - 32s 149ms/step - loss: 0.9606 - accuracy: 0.6433 - val_loss: 0.8943 - val_accuracy: 0.6760\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.89954 to 0.89430, saving model to EmotionDetectionModel.h5\n",
            "Epoch 39/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 0.9596 - accuracy: 0.6449 - val_loss: 0.9002 - val_accuracy: 0.6790\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.89430\n",
            "Epoch 40/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 0.9544 - accuracy: 0.6544 - val_loss: 0.8930 - val_accuracy: 0.6760\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.89430 to 0.89300, saving model to EmotionDetectionModel.h5\n",
            "Epoch 41/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 0.9555 - accuracy: 0.6502 - val_loss: 0.8960 - val_accuracy: 0.6660\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.89300\n",
            "Epoch 42/100\n",
            "210/210 [==============================] - 32s 149ms/step - loss: 0.9458 - accuracy: 0.6547 - val_loss: 0.8871 - val_accuracy: 0.6710\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.89300 to 0.88713, saving model to EmotionDetectionModel.h5\n",
            "Epoch 43/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 0.9457 - accuracy: 0.6522 - val_loss: 0.8639 - val_accuracy: 0.6830\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.88713 to 0.86393, saving model to EmotionDetectionModel.h5\n",
            "Epoch 44/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 0.9317 - accuracy: 0.6558 - val_loss: 0.8898 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.86393\n",
            "Epoch 45/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 0.9321 - accuracy: 0.6570 - val_loss: 0.9178 - val_accuracy: 0.6600\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.86393\n",
            "Epoch 46/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 0.9247 - accuracy: 0.6616 - val_loss: 0.9103 - val_accuracy: 0.6660\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.86393\n",
            "Epoch 47/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 0.9169 - accuracy: 0.6626 - val_loss: 0.8723 - val_accuracy: 0.6810\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.86393\n",
            "Epoch 48/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 0.9199 - accuracy: 0.6642 - val_loss: 0.8544 - val_accuracy: 0.6810\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.86393 to 0.85443, saving model to EmotionDetectionModel.h5\n",
            "Epoch 49/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 0.9047 - accuracy: 0.6653 - val_loss: 0.8787 - val_accuracy: 0.6710\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 0.9102 - accuracy: 0.6620 - val_loss: 0.8761 - val_accuracy: 0.6840\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.85443\n",
            "Epoch 51/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 0.9115 - accuracy: 0.6652 - val_loss: 0.8692 - val_accuracy: 0.6860\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.85443\n",
            "Epoch 52/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 0.9037 - accuracy: 0.6631 - val_loss: 0.8867 - val_accuracy: 0.6880\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.85443\n",
            "Epoch 53/100\n",
            "210/210 [==============================] - 32s 149ms/step - loss: 0.8929 - accuracy: 0.6695 - val_loss: 0.8803 - val_accuracy: 0.6790\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.85443\n",
            "Epoch 54/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 0.8835 - accuracy: 0.6743 - val_loss: 0.8838 - val_accuracy: 0.6850\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.85443\n",
            "Epoch 55/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 0.8965 - accuracy: 0.6712 - val_loss: 0.8930 - val_accuracy: 0.6900\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.85443\n",
            "Epoch 56/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 0.8830 - accuracy: 0.6803 - val_loss: 0.8509 - val_accuracy: 0.6890\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.85443 to 0.85092, saving model to EmotionDetectionModel.h5\n",
            "Epoch 57/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 0.8810 - accuracy: 0.6730 - val_loss: 0.8603 - val_accuracy: 0.6900\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.85092\n",
            "Epoch 58/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 0.8781 - accuracy: 0.6824 - val_loss: 0.8656 - val_accuracy: 0.6840\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.85092\n",
            "Epoch 59/100\n",
            "210/210 [==============================] - 31s 149ms/step - loss: 0.8727 - accuracy: 0.6775 - val_loss: 0.8774 - val_accuracy: 0.6910\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.85092\n",
            "Epoch 60/100\n",
            "210/210 [==============================] - 31s 149ms/step - loss: 0.8686 - accuracy: 0.6822 - val_loss: 0.8634 - val_accuracy: 0.6920\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.85092\n",
            "Epoch 61/100\n",
            "210/210 [==============================] - 31s 149ms/step - loss: 0.8722 - accuracy: 0.6802 - val_loss: 0.8736 - val_accuracy: 0.6870\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.85092\n",
            "Epoch 62/100\n",
            "210/210 [==============================] - 32s 150ms/step - loss: 0.8713 - accuracy: 0.6850 - val_loss: 0.8897 - val_accuracy: 0.6770\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.85092\n",
            "Epoch 63/100\n",
            "210/210 [==============================] - 31s 149ms/step - loss: 0.8667 - accuracy: 0.6778 - val_loss: 0.9096 - val_accuracy: 0.6760\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.85092\n",
            "Epoch 64/100\n",
            "210/210 [==============================] - 32s 149ms/step - loss: 0.8624 - accuracy: 0.6852 - val_loss: 0.8730 - val_accuracy: 0.6870\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.85092\n",
            "Epoch 65/100\n",
            "210/210 [==============================] - 31s 149ms/step - loss: 0.8539 - accuracy: 0.6875 - val_loss: 0.8691 - val_accuracy: 0.6860\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.85092\n",
            "Epoch 66/100\n",
            "210/210 [==============================] - 31s 149ms/step - loss: 0.8502 - accuracy: 0.6872 - val_loss: 0.8729 - val_accuracy: 0.6900\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.85092\n",
            "Epoch 67/100\n",
            "210/210 [==============================] - 32s 149ms/step - loss: 0.8508 - accuracy: 0.6871 - val_loss: 0.8958 - val_accuracy: 0.6890\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.85092\n",
            "Epoch 68/100\n",
            "210/210 [==============================] - 31s 149ms/step - loss: 0.8529 - accuracy: 0.6898 - val_loss: 0.8803 - val_accuracy: 0.6800\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.85092\n",
            "Epoch 69/100\n",
            "210/210 [==============================] - 31s 149ms/step - loss: 0.8506 - accuracy: 0.6884 - val_loss: 0.8807 - val_accuracy: 0.6890\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.85092\n",
            "Epoch 70/100\n",
            "210/210 [==============================] - 31s 148ms/step - loss: 0.8573 - accuracy: 0.6839 - val_loss: 0.8861 - val_accuracy: 0.6910\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.85092\n",
            "Epoch 71/100\n",
            "210/210 [==============================] - 31s 149ms/step - loss: 0.8463 - accuracy: 0.6914 - val_loss: 0.8736 - val_accuracy: 0.6830\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.85092\n",
            "Epoch 72/100\n",
            "210/210 [==============================] - 31s 149ms/step - loss: 0.8343 - accuracy: 0.6965 - val_loss: 0.8756 - val_accuracy: 0.6910\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.85092\n",
            "Epoch 73/100\n",
            "210/210 [==============================] - 31s 149ms/step - loss: 0.8263 - accuracy: 0.7036 - val_loss: 0.8695 - val_accuracy: 0.6830\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.85092\n",
            "Epoch 74/100\n",
            "210/210 [==============================] - 31s 148ms/step - loss: 0.8314 - accuracy: 0.6957 - val_loss: 0.8511 - val_accuracy: 0.6990\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.85092\n",
            "Epoch 75/100\n",
            "210/210 [==============================] - 32s 149ms/step - loss: 0.8439 - accuracy: 0.6932 - val_loss: 0.9167 - val_accuracy: 0.6730\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.85092\n",
            "Epoch 76/100\n",
            "210/210 [==============================] - 31s 149ms/step - loss: 0.8325 - accuracy: 0.6966 - val_loss: 0.8513 - val_accuracy: 0.7140\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.85092\n",
            "\n",
            "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 00076: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lazl2vXx56-v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}